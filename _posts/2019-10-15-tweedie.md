---
title: 'Tweedie models'
date: 2029-12-25
permalink: /posts/2019/10/tweedie/
tags:
  - probability
  - statistics
---

Tweedie distributions are an interesting family of probability distributions that are useful for modeling many 
real-world processes. Here, we'll take a brief tour of the Tweedie family's characteristics, its relationship 
to well-known distributions, and examples of why it might be useful.

## Exponential dispersion models

To understand Tweedie models, it's worth first getting to know their generalization, exponential dispersion models (EDMs). EDMs are a family of probability distributions that can be written in a specific form. Specifically, if a random variable $X$ is distributed according to an EDM with canonical parameter $\theta$ and index parameter $\lambda$ if


$$f_X(x | \theta, \lambda) = h^*(\lambda, x)\exp\{ \theta x - \lambda A(\theta) \}.$$

The experienced reader will notice that this is simply the form of the well-known exponential family with $\eta(\theta) = \theta$ and $T(x) = x)$, plus an extra parameter $\lambda$.

An interesting property of EDMs is that they can be written in two forms. The form in equation (1) is called an additive EDM, and it has the property that sums of additive EDMs are again in the EDM family. In particular, if $Z_i \sim \text{ED}(\theta, \lambda_i)$ for $i = 1, \dots, n$, then 

$$\sum\limits_{i = 1}^n Z_i = Z_+ \sim \text{ED}(\theta, \sum\limits_{i = 1}^n \lambda_i).$$

## Tweedie models

Tweedie distributions are a particular type of EDM in which (in its reproductive form) there's a power law relationship between the mean and variance. Specifically, if $X$ is distributed as an EDM with mean $\mu$ and dispersion $\sigma^2$, and the variance of $X$ can be written as

$$\text{Var}(X) = \sigma^2\mu^p$$

then $X$ is Tweedie-disributed with mean $\mu$, dispersion $\sigma^2$, and power parameter $p$.

Changing the value of $p$ yields remarkably different behavior in the distribution. For example, if $p = 0$, then 

$$\text{Var}(X) = \sigma^2\mu^0 = \sigma^2$$

implying that the variance is constant with respect to the mean. This is precisely the Gaussian distribution.

If $p = 1$, we have

$$\text{Var}(X) = \sigma^2\mu^1 = \sigma^2 \mu$$

implying that the variance scales linearly with the mean. This is the Poisson distribution with dispersion parameter $\sigma^2 = 1$. (A basic property of the Poisson is that the mean and variance are equal).

An interesting, less standard case is when $1 < p < 2$. In this range, it's equivalent to a "compound Poisson-gamma" distribution. Intuitively, a compound Poisson-gamma random variable Y is formed as the sum of individual random variables $X1, \dots, X_N$, each of which is gamma-distributed, and where $N$ is a Poisson-distributed random variable. Concretely,

$$N \sim \text{Poisson}(\lambda)$$

$$X_i \sim \Gamma(\alpha, \beta), i \in \{1, \dots, N\}$$

$$Y = \sum\limits_{i = 1}^N X_i$$


## Tweedie convergence theorem

Now we'll see one of the most amazing results (in my opinion) related to Tweedie distributions. In a 1994 paper, Bent JÃ¸rgensen and colleagues showed that for any EDM with a power law relationship between its mean and variance, as the mean $\mu$ of the EDM becomes large, the distribution will approach a Tweedie distribution. This is basically the central limit theorem, but for distributions with a power law mean-variance relationship.

This result can potentially be used to explain a wide variety of physical phenomenon. A widely studied area where this applies is that of examining the density of animal populations over space or time. For example, many studies have shown that, in a given geographic region, the variance of the population density will be a power of its mean (often a power close to $2$, i.e., $\text{Var}(X) = \mu^2$).

## Fitting a Tweedie model

## Empirical modeling
